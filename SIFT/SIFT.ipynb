{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T10:51:00.590866Z",
     "start_time": "2024-11-23T10:51:00.572866Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T10:51:01.853067Z",
     "start_time": "2024-11-23T10:51:01.841475Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_specific_lookup(data, search_image, template_name):\n",
    "    for entry in data:\n",
    "        if entry[\"search_image\"] == search_image:\n",
    "            for template in entry[\"templates\"]:\n",
    "                if template[\"template\"] == template_name:\n",
    "                    return template\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-23T11:42:02.404359Z",
     "start_time": "2024-11-23T11:42:02.388010Z"
    }
   },
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import image as mpimg\n",
    "\n",
    "#get image pairs\n",
    "base_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "#label path\n",
    "lbl_path = os.path.join(base_path, 'Data/labels/train_template_matching.json')\n",
    "\n",
    "#source and query images\n",
    "s_img_path = os.path.join(base_path, 'Data/map_train/51.99908_4.373749.png')\n",
    "q_img_path = os.path.join(base_path, 'Data/train_template_matching')\n",
    "\n",
    "#for now source path is constant\n",
    "s_img = cv2.imread(s_img_path)\n",
    "\n",
    "with open(lbl_path, 'r') as file:\n",
    "    label = json.load(file)\n",
    "\n",
    "images = []\n",
    "templates = []\n",
    "for file in os.listdir(q_img_path):\n",
    "    if file.endswith(\".jpg\") or file.endswith(\".png\") or file.endswith(\".jpeg\"):\n",
    "            q_img = cv2.imread(os.path.join(q_img_path, file))\n",
    "            images.append([q_img[:, :, :3], s_img[:,:,:3]]) \n",
    "            gps = find_specific_lookup(label, '51.99908_4.373749.png', file)\n",
    "            \n",
    "            templates.append((q_img[:, :, :3], gps))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-23T11:42:17.114274Z",
     "start_time": "2024-11-23T11:42:03.710998Z"
    }
   },
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_features_for_templates(templates, source_image):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    kp_source, des_source = sift.detectAndCompute(source_image, None)\n",
    "    \n",
    "    for template, obj in templates:\n",
    "        kp_template, des_template = sift.detectAndCompute(template, None)\n",
    "        gps_coords = obj['gps_coords']\n",
    "        # Match features\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(des_template, des_source, k=2)\n",
    "        \n",
    "        # Lowe's ratio test\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good_matches.append(m)\n",
    "        \n",
    "        # Extract matched keypoints\n",
    "        src_pts = np.float32([kp_template[m.queryIdx].pt for m in good_matches]).reshape(-1, 2)\n",
    "        dst_pts = np.float32([kp_source[m.trainIdx].pt for m in good_matches]).reshape(-1, 2)\n",
    "        \n",
    "        # Flatten and combine features\n",
    "        src_flat = src_pts.flatten()\n",
    "        dst_flat = dst_pts.flatten()\n",
    "        input_features = np.concatenate([src_flat, dst_flat])\n",
    "        \n",
    "        # Append to feature list\n",
    "        feature_list.append(input_features)\n",
    "        label_list.append(gps_coords)  # GPS coordinates of this template image\n",
    "    max_len = max(len(features) for features in feature_list)\n",
    "    # max_len = 468\n",
    "    padded_features = [np.pad(features, (0, max_len - len(features))) for features in feature_list]\n",
    "\n",
    "    return np.array(padded_features), np.array(label_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-23T11:45:28.282263Z",
     "start_time": "2024-11-23T11:45:28.265256Z"
    }
   },
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train, y_train = extract_features_for_templates(templates, s_img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-23T11:48:12.854907Z",
     "start_time": "2024-11-23T11:45:29.913581Z"
    }
   },
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "def build_model(input_size):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_size,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(2)  # Predict latitude and longitude\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-23T11:48:31.235152Z",
     "start_time": "2024-11-23T11:48:31.229565Z"
    }
   },
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-23T11:48:32.812812Z",
     "start_time": "2024-11-23T11:48:32.807810Z"
    }
   },
   "execution_count": 106
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - loss: 7515.4663 - mae: 61.4331 - val_loss: 665.6019 - val_mae: 19.4431\n",
      "Epoch 2/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 641.4940 - mae: 19.6394 - val_loss: 377.1762 - val_mae: 15.6795\n",
      "Epoch 3/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 266.2264 - mae: 12.8829 - val_loss: 320.7064 - val_mae: 14.2588\n",
      "Epoch 4/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 189.5544 - mae: 10.9163 - val_loss: 245.6886 - val_mae: 12.5996\n",
      "Epoch 5/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 163.2838 - mae: 9.9916 - val_loss: 194.1861 - val_mae: 11.0751\n",
      "Epoch 6/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 130.7165 - mae: 9.0518 - val_loss: 215.4926 - val_mae: 11.9324\n",
      "Epoch 7/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 119.4356 - mae: 8.5485 - val_loss: 145.6314 - val_mae: 9.7390\n",
      "Epoch 8/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 97.3232 - mae: 7.7821 - val_loss: 143.8472 - val_mae: 9.7346\n",
      "Epoch 9/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 76.9408 - mae: 6.7471 - val_loss: 136.8363 - val_mae: 9.4880\n",
      "Epoch 10/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 68.3927 - mae: 6.3978 - val_loss: 114.3148 - val_mae: 8.5402\n",
      "Epoch 11/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 71.1543 - mae: 6.6477 - val_loss: 117.4381 - val_mae: 8.6175\n",
      "Epoch 12/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 52.9347 - mae: 5.6986 - val_loss: 115.0215 - val_mae: 8.6055\n",
      "Epoch 13/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 44.7612 - mae: 5.2562 - val_loss: 95.5002 - val_mae: 7.7626\n",
      "Epoch 14/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 42.9479 - mae: 5.1367 - val_loss: 99.0654 - val_mae: 7.9629\n",
      "Epoch 15/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 36.6821 - mae: 4.8019 - val_loss: 86.4201 - val_mae: 7.3531\n",
      "Epoch 16/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 35.0324 - mae: 4.6346 - val_loss: 86.1864 - val_mae: 7.3542\n",
      "Epoch 17/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 33.4286 - mae: 4.5391 - val_loss: 84.5788 - val_mae: 7.2093\n",
      "Epoch 18/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 25.9934 - mae: 3.9794 - val_loss: 75.9394 - val_mae: 6.8648\n",
      "Epoch 19/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 29.6154 - mae: 4.2727 - val_loss: 83.0015 - val_mae: 7.1408\n",
      "Epoch 20/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 24.1987 - mae: 3.8225 - val_loss: 76.4344 - val_mae: 6.8412\n",
      "Epoch 21/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 22.8270 - mae: 3.6668 - val_loss: 71.2667 - val_mae: 6.6143\n",
      "Epoch 22/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 20.4854 - mae: 3.5079 - val_loss: 72.4165 - val_mae: 6.6360\n",
      "Epoch 23/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 20.7360 - mae: 3.5472 - val_loss: 70.3652 - val_mae: 6.4682\n",
      "Epoch 24/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 18.4670 - mae: 3.3108 - val_loss: 68.1553 - val_mae: 6.3380\n",
      "Epoch 25/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 17.5688 - mae: 3.2141 - val_loss: 70.1334 - val_mae: 6.4675\n",
      "Epoch 26/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 15.8903 - mae: 3.0998 - val_loss: 67.7948 - val_mae: 6.3434\n",
      "Epoch 27/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 16.1663 - mae: 3.1191 - val_loss: 63.1098 - val_mae: 6.1929\n",
      "Epoch 28/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 16.0104 - mae: 3.0628 - val_loss: 63.7391 - val_mae: 6.1545\n",
      "Epoch 29/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 14.6154 - mae: 2.9286 - val_loss: 67.4712 - val_mae: 6.4030\n",
      "Epoch 30/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 13.3734 - mae: 2.7885 - val_loss: 67.7236 - val_mae: 6.3401\n",
      "Epoch 31/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 12.0249 - mae: 2.6510 - val_loss: 63.1718 - val_mae: 6.0857\n",
      "Epoch 32/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 13.2731 - mae: 2.7735 - val_loss: 61.4285 - val_mae: 6.0436\n",
      "Epoch 33/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 10.9058 - mae: 2.5305 - val_loss: 58.9318 - val_mae: 5.9089\n",
      "Epoch 34/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 12.1943 - mae: 2.6247 - val_loss: 60.3905 - val_mae: 5.9416\n",
      "Epoch 35/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 11.1048 - mae: 2.5333 - val_loss: 60.3392 - val_mae: 5.9189\n",
      "Epoch 36/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 9.7119 - mae: 2.3366 - val_loss: 57.8710 - val_mae: 5.8065\n",
      "Epoch 37/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 9.3841 - mae: 2.3147 - val_loss: 56.8946 - val_mae: 5.7607\n",
      "Epoch 38/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 8.9848 - mae: 2.2598 - val_loss: 59.0404 - val_mae: 5.8659\n",
      "Epoch 39/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 9.9879 - mae: 2.4302 - val_loss: 57.4885 - val_mae: 5.7953\n",
      "Epoch 40/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 8.7363 - mae: 2.2684 - val_loss: 56.3832 - val_mae: 5.6903\n",
      "Epoch 41/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 8.3288 - mae: 2.2596 - val_loss: 56.3665 - val_mae: 5.6964\n",
      "Epoch 42/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.7084 - mae: 2.1169 - val_loss: 55.2840 - val_mae: 5.6494\n",
      "Epoch 43/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 7.8348 - mae: 2.1684 - val_loss: 55.6958 - val_mae: 5.7046\n",
      "Epoch 44/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.5345 - mae: 2.0922 - val_loss: 55.7350 - val_mae: 5.6409\n",
      "Epoch 45/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 7.0482 - mae: 2.0299 - val_loss: 55.1059 - val_mae: 5.7171\n",
      "Epoch 46/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.9983 - mae: 1.9866 - val_loss: 56.3171 - val_mae: 5.7491\n",
      "Epoch 47/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 7.0633 - mae: 2.0285 - val_loss: 53.8752 - val_mae: 5.5817\n",
      "Epoch 48/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.9446 - mae: 1.9477 - val_loss: 52.0609 - val_mae: 5.4990\n",
      "Epoch 49/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 5.7545 - mae: 1.8345 - val_loss: 51.8071 - val_mae: 5.5034\n",
      "Epoch 50/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.1536 - mae: 1.9126 - val_loss: 53.8576 - val_mae: 5.5707\n",
      "Epoch 51/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.2223 - mae: 1.8820 - val_loss: 51.5362 - val_mae: 5.4467\n",
      "Epoch 52/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.1470 - mae: 1.8612 - val_loss: 53.2414 - val_mae: 5.5208\n",
      "Epoch 53/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.6923 - mae: 1.9715 - val_loss: 51.4040 - val_mae: 5.4013\n",
      "Epoch 54/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 7.6616 - mae: 2.1342 - val_loss: 53.4027 - val_mae: 5.6143\n",
      "Epoch 55/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 5.7471 - mae: 1.8313 - val_loss: 48.7983 - val_mae: 5.3493\n",
      "Epoch 56/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 5.7201 - mae: 1.8249 - val_loss: 48.8157 - val_mae: 5.3342\n",
      "Epoch 57/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 4.3480 - mae: 1.5959 - val_loss: 50.8562 - val_mae: 5.4460\n",
      "Epoch 58/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 4.8982 - mae: 1.6684 - val_loss: 49.2575 - val_mae: 5.2806\n",
      "Epoch 59/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 4.4287 - mae: 1.6088 - val_loss: 49.5003 - val_mae: 5.3295\n",
      "Epoch 60/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.2869 - mae: 1.5329 - val_loss: 49.0562 - val_mae: 5.3036\n",
      "Epoch 61/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 5.1128 - mae: 1.7387 - val_loss: 51.8926 - val_mae: 5.4838\n",
      "Epoch 62/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.7573 - mae: 1.6478 - val_loss: 47.3378 - val_mae: 5.2212\n",
      "Epoch 63/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.3587 - mae: 1.5340 - val_loss: 46.8894 - val_mae: 5.2084\n",
      "Epoch 64/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.3574 - mae: 1.5743 - val_loss: 47.2515 - val_mae: 5.2733\n",
      "Epoch 65/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 5.3034 - mae: 1.7420 - val_loss: 46.4387 - val_mae: 5.1861\n",
      "Epoch 66/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 5.1046 - mae: 1.7056 - val_loss: 48.8950 - val_mae: 5.3195\n",
      "Epoch 67/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 4.1682 - mae: 1.5320 - val_loss: 50.5932 - val_mae: 5.4376\n",
      "Epoch 68/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.4360 - mae: 1.6315 - val_loss: 46.9476 - val_mae: 5.1828\n",
      "Epoch 69/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.5545 - mae: 1.4195 - val_loss: 46.6254 - val_mae: 5.1770\n",
      "Epoch 70/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.5356 - mae: 1.4317 - val_loss: 46.9446 - val_mae: 5.1938\n",
      "Epoch 71/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.3040 - mae: 1.3614 - val_loss: 46.5228 - val_mae: 5.1598\n",
      "Epoch 72/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.3850 - mae: 1.3918 - val_loss: 47.8800 - val_mae: 5.2155\n",
      "Epoch 73/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.4646 - mae: 1.4119 - val_loss: 46.0123 - val_mae: 5.1770\n",
      "Epoch 74/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.4901 - mae: 1.4458 - val_loss: 46.6246 - val_mae: 5.1624\n",
      "Epoch 75/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.1425 - mae: 1.3249 - val_loss: 47.0268 - val_mae: 5.2031\n",
      "Epoch 76/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.9921 - mae: 1.2984 - val_loss: 45.8551 - val_mae: 5.1376\n",
      "Epoch 77/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.8484 - mae: 1.2812 - val_loss: 45.0654 - val_mae: 5.0738\n",
      "Epoch 78/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.5946 - mae: 1.2200 - val_loss: 45.3209 - val_mae: 5.1230\n",
      "Epoch 79/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.7841 - mae: 1.2491 - val_loss: 43.8661 - val_mae: 4.9929\n",
      "Epoch 80/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.7131 - mae: 1.2745 - val_loss: 44.1884 - val_mae: 4.9831\n",
      "Epoch 81/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.0812 - mae: 1.3624 - val_loss: 46.4655 - val_mae: 5.1819\n",
      "Epoch 82/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.8714 - mae: 1.3254 - val_loss: 44.3678 - val_mae: 5.0556\n",
      "Epoch 83/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.6846 - mae: 1.2616 - val_loss: 45.0349 - val_mae: 5.0870\n",
      "Epoch 84/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.7637 - mae: 1.2647 - val_loss: 43.9697 - val_mae: 5.0336\n",
      "Epoch 85/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.3242 - mae: 1.1753 - val_loss: 43.0612 - val_mae: 4.9516\n",
      "Epoch 86/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.7091 - mae: 1.2417 - val_loss: 42.7615 - val_mae: 4.9046\n",
      "Epoch 87/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.3668 - mae: 1.1971 - val_loss: 41.8933 - val_mae: 4.8616\n",
      "Epoch 88/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.7458 - mae: 1.2742 - val_loss: 44.2655 - val_mae: 4.9944\n",
      "Epoch 89/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.5527 - mae: 1.4411 - val_loss: 42.8272 - val_mae: 4.9319\n",
      "Epoch 90/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.3162 - mae: 1.3598 - val_loss: 41.6146 - val_mae: 4.8925\n",
      "Epoch 91/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.3530 - mae: 1.1572 - val_loss: 42.1024 - val_mae: 4.8554\n",
      "Epoch 92/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.3301 - mae: 1.1671 - val_loss: 42.3092 - val_mae: 4.8821\n",
      "Epoch 93/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.1977 - mae: 1.1400 - val_loss: 42.6477 - val_mae: 4.9481\n",
      "Epoch 94/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.1264 - mae: 1.1259 - val_loss: 41.8076 - val_mae: 4.8961\n",
      "Epoch 95/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.1488 - mae: 1.1244 - val_loss: 42.3768 - val_mae: 4.9200\n",
      "Epoch 96/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.0315 - mae: 1.1123 - val_loss: 41.8364 - val_mae: 4.8656\n",
      "Epoch 97/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.4017 - mae: 1.1780 - val_loss: 44.0112 - val_mae: 5.0271\n",
      "Epoch 98/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.2687 - mae: 1.1336 - val_loss: 41.8780 - val_mae: 4.8709\n",
      "Epoch 99/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.7956 - mae: 1.2685 - val_loss: 42.2490 - val_mae: 4.9779\n",
      "Epoch 100/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.4495 - mae: 1.2167 - val_loss: 41.9874 - val_mae: 4.9630\n",
      "Epoch 101/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.7364 - mae: 1.2532 - val_loss: 41.3254 - val_mae: 4.8365\n",
      "Epoch 102/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.7490 - mae: 1.2218 - val_loss: 39.3394 - val_mae: 4.7048\n",
      "Epoch 103/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.2561 - mae: 1.1312 - val_loss: 40.8882 - val_mae: 4.8330\n",
      "Epoch 104/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.0810 - mae: 1.0937 - val_loss: 40.8755 - val_mae: 4.8428\n",
      "Epoch 105/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.0227 - mae: 1.2748 - val_loss: 39.7792 - val_mae: 4.7401\n",
      "Epoch 106/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.4277 - mae: 1.1644 - val_loss: 40.5874 - val_mae: 4.8618\n",
      "Epoch 107/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.3253 - mae: 1.3511 - val_loss: 39.4790 - val_mae: 4.7003\n",
      "Epoch 108/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.0740 - mae: 1.2773 - val_loss: 37.4166 - val_mae: 4.6284\n",
      "Epoch 109/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.5854 - mae: 1.6272 - val_loss: 37.1238 - val_mae: 4.6585\n",
      "Epoch 110/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.0147 - mae: 1.9277 - val_loss: 41.7035 - val_mae: 4.9436\n",
      "Epoch 111/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 13.7880 - mae: 2.4255 - val_loss: 43.5962 - val_mae: 4.9970\n",
      "Epoch 112/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 24.2609 - mae: 3.0865 - val_loss: 36.1157 - val_mae: 4.6304\n",
      "Epoch 113/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 10.3812 - mae: 2.4724 - val_loss: 37.5498 - val_mae: 4.6489\n",
      "Epoch 114/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 9.5139 - mae: 2.3711 - val_loss: 36.6258 - val_mae: 4.5967\n",
      "Epoch 115/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 10.6546 - mae: 2.4855 - val_loss: 30.6153 - val_mae: 4.1717\n",
      "Epoch 116/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.9747 - mae: 2.0396 - val_loss: 27.7337 - val_mae: 4.0605\n",
      "Epoch 117/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.1667 - mae: 1.5478 - val_loss: 31.5294 - val_mae: 4.3133\n",
      "Epoch 118/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.3542 - mae: 1.4111 - val_loss: 27.8296 - val_mae: 4.0256\n",
      "Epoch 119/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.9437 - mae: 1.3312 - val_loss: 29.4297 - val_mae: 4.0818\n",
      "Epoch 120/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.8084 - mae: 1.2645 - val_loss: 29.9190 - val_mae: 4.1767\n",
      "Epoch 121/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.3062 - mae: 1.4153 - val_loss: 29.2383 - val_mae: 4.0857\n",
      "Epoch 122/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.9007 - mae: 1.0618 - val_loss: 27.3676 - val_mae: 3.9639\n",
      "Epoch 123/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.6094 - mae: 1.2527 - val_loss: 30.3323 - val_mae: 4.2057\n",
      "Epoch 124/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.9633 - mae: 1.0654 - val_loss: 28.3107 - val_mae: 4.0472\n",
      "Epoch 125/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.9047 - mae: 1.0617 - val_loss: 28.8291 - val_mae: 4.0517\n",
      "Epoch 126/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.6940 - mae: 1.0097 - val_loss: 27.4893 - val_mae: 3.9605\n",
      "Epoch 127/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.5152 - mae: 0.9564 - val_loss: 28.0112 - val_mae: 3.9907\n",
      "Epoch 128/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3552 - mae: 0.9041 - val_loss: 27.8539 - val_mae: 4.0036\n",
      "Epoch 129/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.1859 - mae: 0.8518 - val_loss: 29.0526 - val_mae: 4.0744\n",
      "Epoch 130/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.3065 - mae: 0.8701 - val_loss: 27.1401 - val_mae: 3.9382\n",
      "Epoch 131/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.2843 - mae: 0.8729 - val_loss: 27.3316 - val_mae: 3.9460\n",
      "Epoch 132/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1662 - mae: 0.8434 - val_loss: 27.6037 - val_mae: 3.9826\n",
      "Epoch 133/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.2346 - mae: 0.8536 - val_loss: 28.3169 - val_mae: 4.0260\n",
      "Epoch 134/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.2652 - mae: 0.8552 - val_loss: 27.4698 - val_mae: 3.9513\n",
      "Epoch 135/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.3277 - mae: 0.8891 - val_loss: 27.7291 - val_mae: 3.9847\n",
      "Epoch 136/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0660 - mae: 0.7939 - val_loss: 28.5743 - val_mae: 4.0603\n",
      "Epoch 137/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8958 - mae: 0.7302 - val_loss: 27.3620 - val_mae: 3.9323\n",
      "Epoch 138/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0728 - mae: 0.8024 - val_loss: 27.6821 - val_mae: 3.9656\n",
      "Epoch 139/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9873 - mae: 0.7701 - val_loss: 27.4969 - val_mae: 3.9370\n",
      "Epoch 140/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9942 - mae: 0.7740 - val_loss: 27.3133 - val_mae: 3.9326\n",
      "Epoch 141/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.9112 - mae: 0.7325 - val_loss: 27.1771 - val_mae: 3.9252\n",
      "Epoch 142/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.8439 - mae: 0.7152 - val_loss: 26.7999 - val_mae: 3.8780\n",
      "Epoch 143/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.9786 - mae: 0.7608 - val_loss: 26.6215 - val_mae: 3.8662\n",
      "Epoch 144/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.8955 - mae: 0.7265 - val_loss: 27.9216 - val_mae: 4.0081\n",
      "Epoch 145/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0763 - mae: 0.8099 - val_loss: 27.3533 - val_mae: 3.9077\n",
      "Epoch 146/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3115 - mae: 0.8992 - val_loss: 26.3252 - val_mae: 3.8355\n",
      "Epoch 147/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.2445 - mae: 0.8761 - val_loss: 27.4853 - val_mae: 3.9392\n",
      "Epoch 148/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.9223 - mae: 0.7451 - val_loss: 26.9426 - val_mae: 3.8938\n",
      "Epoch 149/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8508 - mae: 0.7105 - val_loss: 26.7451 - val_mae: 3.8613\n",
      "Epoch 150/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0166 - mae: 0.7780 - val_loss: 26.3619 - val_mae: 3.8277\n",
      "Epoch 151/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1354 - mae: 0.8242 - val_loss: 27.2731 - val_mae: 3.8948\n",
      "Epoch 152/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.2136 - mae: 0.8577 - val_loss: 26.8570 - val_mae: 3.8727\n",
      "Epoch 153/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.9227 - mae: 0.7485 - val_loss: 27.0162 - val_mae: 3.8739\n",
      "Epoch 154/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7336 - mae: 0.6701 - val_loss: 26.6649 - val_mae: 3.8570\n",
      "Epoch 155/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6825 - mae: 0.6338 - val_loss: 26.7891 - val_mae: 3.8621\n",
      "Epoch 156/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7682 - mae: 0.6770 - val_loss: 26.8632 - val_mae: 3.8945\n",
      "Epoch 157/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6672 - mae: 0.6380 - val_loss: 26.4012 - val_mae: 3.8343\n",
      "Epoch 158/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5807 - mae: 0.5788 - val_loss: 26.2276 - val_mae: 3.8138\n",
      "Epoch 159/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5545 - mae: 0.5654 - val_loss: 26.7198 - val_mae: 3.8557\n",
      "Epoch 160/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.6646 - mae: 0.6329 - val_loss: 26.7008 - val_mae: 3.8567\n",
      "Epoch 161/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7333 - mae: 0.6730 - val_loss: 26.3541 - val_mae: 3.8161\n",
      "Epoch 162/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5434 - mae: 0.5573 - val_loss: 26.3186 - val_mae: 3.8213\n",
      "Epoch 163/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5737 - mae: 0.5706 - val_loss: 25.7905 - val_mae: 3.7846\n",
      "Epoch 164/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.8503 - mae: 0.6898 - val_loss: 25.9139 - val_mae: 3.8040\n",
      "Epoch 165/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.9027 - mae: 0.7013 - val_loss: 25.9350 - val_mae: 3.8043\n",
      "Epoch 166/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0822 - mae: 0.7880 - val_loss: 25.1575 - val_mae: 3.7689\n",
      "Epoch 167/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3195 - mae: 0.8364 - val_loss: 25.3156 - val_mae: 3.7681\n",
      "Epoch 168/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.6506 - mae: 0.9123 - val_loss: 26.3344 - val_mae: 3.8010\n",
      "Epoch 169/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.5805 - mae: 0.8932 - val_loss: 25.1378 - val_mae: 3.7916\n",
      "Epoch 170/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0495 - mae: 0.7507 - val_loss: 24.5622 - val_mae: 3.6935\n",
      "Epoch 171/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9807 - mae: 0.7546 - val_loss: 24.7271 - val_mae: 3.6938\n",
      "Epoch 172/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9520 - mae: 0.7453 - val_loss: 25.9331 - val_mae: 3.7902\n",
      "Epoch 173/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.4040 - mae: 0.9062 - val_loss: 25.4739 - val_mae: 3.7346\n",
      "Epoch 174/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8647 - mae: 0.7018 - val_loss: 25.6886 - val_mae: 3.7490\n",
      "Epoch 175/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.5233 - mae: 0.9288 - val_loss: 25.3376 - val_mae: 3.7307\n",
      "Epoch 176/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1779 - mae: 0.8467 - val_loss: 25.4133 - val_mae: 3.7571\n",
      "Epoch 177/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.6416 - mae: 0.9076 - val_loss: 24.8256 - val_mae: 3.6926\n",
      "Epoch 178/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3279 - mae: 0.8085 - val_loss: 23.8910 - val_mae: 3.6247\n",
      "Epoch 179/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8204 - mae: 0.6943 - val_loss: 24.2417 - val_mae: 3.6557\n",
      "Epoch 180/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8637 - mae: 0.7335 - val_loss: 23.9574 - val_mae: 3.6461\n",
      "Epoch 181/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6960 - mae: 0.6452 - val_loss: 23.5728 - val_mae: 3.6061\n",
      "Epoch 182/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5633 - mae: 0.5852 - val_loss: 24.0540 - val_mae: 3.6771\n",
      "Epoch 183/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5905 - mae: 0.6029 - val_loss: 24.5555 - val_mae: 3.6481\n",
      "Epoch 184/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8266 - mae: 0.6911 - val_loss: 23.8158 - val_mae: 3.6415\n",
      "Epoch 185/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5353 - mae: 0.5594 - val_loss: 23.8450 - val_mae: 3.6369\n",
      "Epoch 186/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7269 - mae: 0.6371 - val_loss: 24.3417 - val_mae: 3.6962\n",
      "Epoch 187/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6028 - mae: 0.5860 - val_loss: 23.8373 - val_mae: 3.6292\n",
      "Epoch 188/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7672 - mae: 0.6597 - val_loss: 23.5396 - val_mae: 3.5931\n",
      "Epoch 189/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9471 - mae: 0.7404 - val_loss: 23.4340 - val_mae: 3.6061\n",
      "Epoch 190/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0200 - mae: 0.7995 - val_loss: 24.0675 - val_mae: 3.6659\n",
      "Epoch 191/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0310 - mae: 0.7707 - val_loss: 23.6617 - val_mae: 3.6034\n",
      "Epoch 192/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.9463 - mae: 0.7382 - val_loss: 24.1964 - val_mae: 3.6382\n",
      "Epoch 193/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.5807 - mae: 0.9970 - val_loss: 24.5617 - val_mae: 3.6594\n",
      "Epoch 194/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.2956 - mae: 0.8259 - val_loss: 23.2645 - val_mae: 3.6034\n",
      "Epoch 195/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.6189 - mae: 0.9860 - val_loss: 24.9565 - val_mae: 3.7153\n",
      "Epoch 196/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.9601 - mae: 1.0711 - val_loss: 23.3286 - val_mae: 3.5831\n",
      "Epoch 197/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.1355 - mae: 1.1380 - val_loss: 22.9601 - val_mae: 3.5970\n",
      "Epoch 198/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.5852 - mae: 0.9619 - val_loss: 22.5365 - val_mae: 3.5220\n",
      "Epoch 199/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.3177 - mae: 0.8673 - val_loss: 22.6575 - val_mae: 3.4818\n",
      "Epoch 200/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0078 - mae: 0.7675 - val_loss: 21.7124 - val_mae: 3.4527\n",
      "Epoch 201/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.0995 - mae: 0.8052 - val_loss: 22.0880 - val_mae: 3.4659\n",
      "Epoch 202/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.8428 - mae: 0.6749 - val_loss: 22.4497 - val_mae: 3.5053\n",
      "Epoch 203/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5736 - mae: 0.5764 - val_loss: 21.8943 - val_mae: 3.4572\n",
      "Epoch 204/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6577 - mae: 0.6037 - val_loss: 22.4024 - val_mae: 3.4719\n",
      "Epoch 205/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1108 - mae: 0.7620 - val_loss: 22.7485 - val_mae: 3.5671\n",
      "Epoch 206/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.0139 - mae: 1.0897 - val_loss: 22.9406 - val_mae: 3.5675\n",
      "Epoch 207/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.2089 - mae: 0.8029 - val_loss: 21.1046 - val_mae: 3.4229\n",
      "Epoch 208/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0486 - mae: 0.7336 - val_loss: 21.6593 - val_mae: 3.4408\n",
      "Epoch 209/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7704 - mae: 0.6258 - val_loss: 22.5804 - val_mae: 3.4777\n",
      "Epoch 210/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1612 - mae: 0.8274 - val_loss: 21.1595 - val_mae: 3.3699\n",
      "Epoch 211/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9668 - mae: 0.7527 - val_loss: 21.0578 - val_mae: 3.3947\n",
      "Epoch 212/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8996 - mae: 0.7248 - val_loss: 21.3842 - val_mae: 3.3785\n",
      "Epoch 213/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.5647 - mae: 0.9322 - val_loss: 21.3224 - val_mae: 3.4178\n",
      "Epoch 214/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.5558 - mae: 0.9346 - val_loss: 21.0674 - val_mae: 3.3705\n",
      "Epoch 215/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.3286 - mae: 0.8559 - val_loss: 21.9030 - val_mae: 3.4633\n",
      "Epoch 216/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.3313 - mae: 1.1678 - val_loss: 22.0218 - val_mae: 3.5132\n",
      "Epoch 217/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.0752 - mae: 1.2544 - val_loss: 21.2519 - val_mae: 3.3526\n",
      "Epoch 218/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 6.0712 - mae: 1.6994 - val_loss: 20.9321 - val_mae: 3.2718\n",
      "Epoch 219/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.2976 - mae: 1.8075 - val_loss: 20.3439 - val_mae: 3.2823\n",
      "Epoch 220/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.4172 - mae: 1.3633 - val_loss: 18.1024 - val_mae: 3.1238\n",
      "Epoch 221/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.2638 - mae: 1.1193 - val_loss: 18.5831 - val_mae: 3.2369\n",
      "Epoch 222/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.0984 - mae: 1.1370 - val_loss: 18.2141 - val_mae: 3.1454\n",
      "Epoch 223/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.6247 - mae: 0.9781 - val_loss: 17.6423 - val_mae: 3.0887\n",
      "Epoch 224/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.6977 - mae: 0.9561 - val_loss: 17.4290 - val_mae: 3.0566\n",
      "Epoch 225/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8881 - mae: 0.6964 - val_loss: 16.8239 - val_mae: 3.0366\n",
      "Epoch 226/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9917 - mae: 0.7003 - val_loss: 17.0690 - val_mae: 3.0398\n",
      "Epoch 227/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.2072 - mae: 0.8310 - val_loss: 17.5251 - val_mae: 3.0797\n",
      "Epoch 228/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.8361 - mae: 0.6999 - val_loss: 17.4236 - val_mae: 3.0579\n",
      "Epoch 229/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6444 - mae: 0.5978 - val_loss: 17.7497 - val_mae: 3.1132\n",
      "Epoch 230/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6310 - mae: 0.6042 - val_loss: 17.6815 - val_mae: 3.0853\n",
      "Epoch 231/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5299 - mae: 0.5463 - val_loss: 17.3066 - val_mae: 3.0701\n",
      "Epoch 232/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5962 - mae: 0.5861 - val_loss: 17.3131 - val_mae: 3.0790\n",
      "Epoch 233/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.6232 - mae: 0.6045 - val_loss: 17.5040 - val_mae: 3.0840\n",
      "Epoch 234/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4890 - mae: 0.5436 - val_loss: 17.4618 - val_mae: 3.0757\n",
      "Epoch 235/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4988 - mae: 0.5252 - val_loss: 16.5759 - val_mae: 3.0029\n",
      "Epoch 236/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7863 - mae: 0.6482 - val_loss: 17.9617 - val_mae: 3.1001\n",
      "Epoch 237/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5806 - mae: 0.5646 - val_loss: 17.6986 - val_mae: 3.0655\n",
      "Epoch 238/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8497 - mae: 0.6874 - val_loss: 17.1771 - val_mae: 3.0174\n",
      "Epoch 239/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9485 - mae: 0.7306 - val_loss: 17.1562 - val_mae: 3.0236\n",
      "Epoch 240/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6578 - mae: 0.5903 - val_loss: 17.5561 - val_mae: 3.0751\n",
      "Epoch 241/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5142 - mae: 0.5057 - val_loss: 16.9510 - val_mae: 2.9975\n",
      "Epoch 242/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1802 - mae: 0.7588 - val_loss: 17.7983 - val_mae: 3.0864\n",
      "Epoch 243/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1210 - mae: 0.7155 - val_loss: 17.1485 - val_mae: 3.0288\n",
      "Epoch 244/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0418 - mae: 0.6408 - val_loss: 16.8008 - val_mae: 2.9393\n",
      "Epoch 245/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.9227 - mae: 0.6896 - val_loss: 16.8326 - val_mae: 2.9819\n",
      "Epoch 246/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.6852 - mae: 0.5809 - val_loss: 16.8944 - val_mae: 2.9750\n",
      "Epoch 247/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4986 - mae: 0.4968 - val_loss: 16.4705 - val_mae: 2.9784\n",
      "Epoch 248/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6726 - mae: 0.6156 - val_loss: 16.1856 - val_mae: 2.9303\n",
      "Epoch 249/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7174 - mae: 0.6140 - val_loss: 18.1669 - val_mae: 3.1011\n",
      "Epoch 250/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9295 - mae: 0.6976 - val_loss: 17.2931 - val_mae: 3.0366\n",
      "Epoch 251/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.9157 - mae: 0.7129 - val_loss: 17.7062 - val_mae: 3.0358\n",
      "Epoch 252/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.7559 - mae: 0.6305 - val_loss: 16.0306 - val_mae: 2.9194\n",
      "Epoch 253/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.9888 - mae: 0.7468 - val_loss: 16.4074 - val_mae: 2.9625\n",
      "Epoch 254/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.1653 - mae: 0.7889 - val_loss: 17.2132 - val_mae: 3.0121\n",
      "Epoch 255/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.2252 - mae: 0.8060 - val_loss: 16.1071 - val_mae: 2.9292\n",
      "Epoch 256/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.8232 - mae: 0.6695 - val_loss: 17.1005 - val_mae: 2.9838\n",
      "Epoch 257/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.1656 - mae: 0.8127 - val_loss: 15.8887 - val_mae: 2.8897\n",
      "Epoch 258/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.4779 - mae: 0.5287 - val_loss: 16.2670 - val_mae: 2.9159\n",
      "Epoch 259/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3195 - mae: 0.4298 - val_loss: 16.3273 - val_mae: 2.9271\n",
      "Epoch 260/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3161 - mae: 0.4277 - val_loss: 15.9831 - val_mae: 2.9152\n",
      "Epoch 261/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3303 - mae: 0.4479 - val_loss: 16.0844 - val_mae: 2.9068\n",
      "Epoch 262/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3067 - mae: 0.3954 - val_loss: 16.0281 - val_mae: 2.8970\n",
      "Epoch 263/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.4072 - mae: 0.4903 - val_loss: 16.5631 - val_mae: 2.9410\n",
      "Epoch 264/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3117 - mae: 0.4286 - val_loss: 16.5632 - val_mae: 2.9426\n",
      "Epoch 265/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3105 - mae: 0.4288 - val_loss: 16.5737 - val_mae: 2.9445\n",
      "Epoch 266/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3204 - mae: 0.4005 - val_loss: 16.4273 - val_mae: 2.9226\n",
      "Epoch 267/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2601 - mae: 0.3835 - val_loss: 15.7209 - val_mae: 2.8783\n",
      "Epoch 268/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5667 - mae: 0.5680 - val_loss: 16.5571 - val_mae: 2.9248\n",
      "Epoch 269/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2996 - mae: 0.3938 - val_loss: 15.6906 - val_mae: 2.8592\n",
      "Epoch 270/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5469 - mae: 0.5408 - val_loss: 17.3049 - val_mae: 3.0152\n",
      "Epoch 271/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.8100 - mae: 0.6578 - val_loss: 16.0233 - val_mae: 2.8779\n",
      "Epoch 272/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1194 - mae: 0.7249 - val_loss: 17.4720 - val_mae: 2.9645\n",
      "Epoch 273/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.1983 - mae: 1.0654 - val_loss: 15.9675 - val_mae: 2.8701\n",
      "Epoch 274/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.0306 - mae: 1.0816 - val_loss: 15.8735 - val_mae: 2.8195\n",
      "Epoch 275/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.9944 - mae: 1.0645 - val_loss: 14.9028 - val_mae: 2.7333\n",
      "Epoch 276/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.3001 - mae: 0.8086 - val_loss: 16.0063 - val_mae: 2.8230\n",
      "Epoch 277/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.7368 - mae: 0.9784 - val_loss: 14.1407 - val_mae: 2.7207\n",
      "Epoch 278/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.1714 - mae: 1.1119 - val_loss: 16.4805 - val_mae: 2.8665\n",
      "Epoch 279/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.6363 - mae: 1.1714 - val_loss: 16.2450 - val_mae: 2.8486\n",
      "Epoch 280/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.7568 - mae: 1.2143 - val_loss: 15.3990 - val_mae: 2.7378\n",
      "Epoch 281/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.2126 - mae: 1.1166 - val_loss: 14.2865 - val_mae: 2.6773\n",
      "Epoch 282/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3952 - mae: 0.8614 - val_loss: 13.9576 - val_mae: 2.5920\n",
      "Epoch 283/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9091 - mae: 0.7167 - val_loss: 14.2648 - val_mae: 2.6786\n",
      "Epoch 284/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8201 - mae: 0.6805 - val_loss: 15.5820 - val_mae: 2.7645\n",
      "Epoch 285/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0118 - mae: 0.6763 - val_loss: 14.5902 - val_mae: 2.6872\n",
      "Epoch 286/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7822 - mae: 0.6458 - val_loss: 14.9979 - val_mae: 2.6968\n",
      "Epoch 287/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4994 - mae: 0.5320 - val_loss: 14.0473 - val_mae: 2.6226\n",
      "Epoch 288/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5692 - mae: 0.5421 - val_loss: 14.9967 - val_mae: 2.6834\n",
      "Epoch 289/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.6319 - mae: 0.6092 - val_loss: 14.7571 - val_mae: 2.6826\n",
      "Epoch 290/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7800 - mae: 0.6644 - val_loss: 15.4624 - val_mae: 2.7245\n",
      "Epoch 291/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8600 - mae: 0.6868 - val_loss: 14.1193 - val_mae: 2.6078\n",
      "Epoch 292/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4785 - mae: 0.4967 - val_loss: 14.8867 - val_mae: 2.6863\n",
      "Epoch 293/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5803 - mae: 0.5786 - val_loss: 14.5526 - val_mae: 2.6473\n",
      "Epoch 294/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.6419 - mae: 0.5633 - val_loss: 13.4439 - val_mae: 2.5558\n",
      "Epoch 295/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5225 - mae: 0.5368 - val_loss: 14.3182 - val_mae: 2.6486\n",
      "Epoch 296/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5441 - mae: 0.5074 - val_loss: 14.1110 - val_mae: 2.6314\n",
      "Epoch 297/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6595 - mae: 0.5498 - val_loss: 13.6703 - val_mae: 2.5874\n",
      "Epoch 298/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.7741 - mae: 0.6120 - val_loss: 14.5516 - val_mae: 2.6180\n",
      "Epoch 299/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6945 - mae: 0.5706 - val_loss: 13.9586 - val_mae: 2.5770\n",
      "Epoch 300/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7078 - mae: 0.5930 - val_loss: 14.0358 - val_mae: 2.5846\n",
      "Epoch 301/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3130 - mae: 0.8145 - val_loss: 16.0052 - val_mae: 2.7692\n",
      "Epoch 302/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.7003 - mae: 0.9544 - val_loss: 15.7177 - val_mae: 2.7023\n",
      "Epoch 303/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.8374 - mae: 0.9832 - val_loss: 14.1080 - val_mae: 2.5452\n",
      "Epoch 304/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.8657 - mae: 1.0152 - val_loss: 14.2238 - val_mae: 2.5385\n",
      "Epoch 305/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.4362 - mae: 1.1409 - val_loss: 13.4587 - val_mae: 2.5423\n",
      "Epoch 306/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.9283 - mae: 1.2666 - val_loss: 14.0766 - val_mae: 2.6125\n",
      "Epoch 307/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.2619 - mae: 1.3199 - val_loss: 12.7212 - val_mae: 2.3492\n",
      "Epoch 308/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.9579 - mae: 1.5461 - val_loss: 13.8836 - val_mae: 2.4927\n",
      "Epoch 309/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.1026 - mae: 1.4000 - val_loss: 12.6505 - val_mae: 2.3889\n",
      "Epoch 310/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 4.3436 - mae: 1.4746 - val_loss: 11.4882 - val_mae: 2.3026\n",
      "Epoch 311/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.5059 - mae: 0.8643 - val_loss: 12.0284 - val_mae: 2.3010\n",
      "Epoch 312/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.5484 - mae: 0.8943 - val_loss: 12.8054 - val_mae: 2.3863\n",
      "Epoch 313/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3584 - mae: 0.8451 - val_loss: 12.8243 - val_mae: 2.3784\n",
      "Epoch 314/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0950 - mae: 0.7793 - val_loss: 10.7895 - val_mae: 2.1888\n",
      "Epoch 315/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.6024 - mae: 0.5773 - val_loss: 11.1518 - val_mae: 2.2044\n",
      "Epoch 316/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6096 - mae: 0.5884 - val_loss: 10.7162 - val_mae: 2.1735\n",
      "Epoch 317/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5890 - mae: 0.5764 - val_loss: 11.2562 - val_mae: 2.2157\n",
      "Epoch 318/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3653 - mae: 0.4607 - val_loss: 10.5551 - val_mae: 2.1621\n",
      "Epoch 319/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2981 - mae: 0.4233 - val_loss: 11.1456 - val_mae: 2.2061\n",
      "Epoch 320/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3935 - mae: 0.4815 - val_loss: 10.8736 - val_mae: 2.1844\n",
      "Epoch 321/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2894 - mae: 0.4110 - val_loss: 10.6816 - val_mae: 2.1576\n",
      "Epoch 322/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2672 - mae: 0.3895 - val_loss: 11.2743 - val_mae: 2.2159\n",
      "Epoch 323/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2312 - mae: 0.3690 - val_loss: 11.1580 - val_mae: 2.1957\n",
      "Epoch 324/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3122 - mae: 0.4165 - val_loss: 11.3716 - val_mae: 2.2159\n",
      "Epoch 325/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2898 - mae: 0.3963 - val_loss: 10.7177 - val_mae: 2.1388\n",
      "Epoch 326/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3646 - mae: 0.4416 - val_loss: 12.0211 - val_mae: 2.2784\n",
      "Epoch 327/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5232 - mae: 0.5097 - val_loss: 10.9454 - val_mae: 2.1705\n",
      "Epoch 328/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3884 - mae: 0.4253 - val_loss: 11.3880 - val_mae: 2.2192\n",
      "Epoch 329/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4036 - mae: 0.4199 - val_loss: 10.8406 - val_mae: 2.1651\n",
      "Epoch 330/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3399 - mae: 0.4009 - val_loss: 11.3799 - val_mae: 2.2003\n",
      "Epoch 331/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3569 - mae: 0.4353 - val_loss: 10.9283 - val_mae: 2.1863\n",
      "Epoch 332/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3229 - mae: 0.4220 - val_loss: 11.3443 - val_mae: 2.1970\n",
      "Epoch 333/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4290 - mae: 0.4542 - val_loss: 10.5925 - val_mae: 2.1089\n",
      "Epoch 334/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5963 - mae: 0.5583 - val_loss: 11.7367 - val_mae: 2.2452\n",
      "Epoch 335/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5698 - mae: 0.5509 - val_loss: 11.4141 - val_mae: 2.1796\n",
      "Epoch 336/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5682 - mae: 0.5402 - val_loss: 10.9998 - val_mae: 2.1547\n",
      "Epoch 337/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6017 - mae: 0.5505 - val_loss: 11.1171 - val_mae: 2.1494\n",
      "Epoch 338/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.4189 - mae: 0.4587 - val_loss: 10.9500 - val_mae: 2.1722\n",
      "Epoch 339/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2823 - mae: 0.3902 - val_loss: 11.1084 - val_mae: 2.1643\n",
      "Epoch 340/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2008 - mae: 0.3221 - val_loss: 11.1447 - val_mae: 2.1819\n",
      "Epoch 341/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.1487 - mae: 0.2887 - val_loss: 10.9143 - val_mae: 2.1505\n",
      "Epoch 342/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.1390 - mae: 0.2805 - val_loss: 11.2051 - val_mae: 2.1901\n",
      "Epoch 343/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1676 - mae: 0.3117 - val_loss: 10.8624 - val_mae: 2.1589\n",
      "Epoch 344/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.1747 - mae: 0.3175 - val_loss: 11.1557 - val_mae: 2.1614\n",
      "Epoch 345/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2437 - mae: 0.3565 - val_loss: 10.9518 - val_mae: 2.1568\n",
      "Epoch 346/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3897 - mae: 0.4298 - val_loss: 10.9731 - val_mae: 2.1545\n",
      "Epoch 347/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2780 - mae: 0.3688 - val_loss: 11.5867 - val_mae: 2.1943\n",
      "Epoch 348/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4554 - mae: 0.4589 - val_loss: 11.0814 - val_mae: 2.1695\n",
      "Epoch 349/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4918 - mae: 0.4964 - val_loss: 10.8508 - val_mae: 2.1401\n",
      "Epoch 350/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9206 - mae: 0.6467 - val_loss: 11.3564 - val_mae: 2.1774\n",
      "Epoch 351/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 1.1194 - mae: 0.7233 - val_loss: 10.7752 - val_mae: 2.1668\n",
      "Epoch 352/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.6921 - mae: 0.8840 - val_loss: 10.9863 - val_mae: 2.1019\n",
      "Epoch 353/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.6024 - mae: 0.8385 - val_loss: 9.8966 - val_mae: 2.0662\n",
      "Epoch 354/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.7668 - mae: 1.1128 - val_loss: 11.1087 - val_mae: 2.1101\n",
      "Epoch 355/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.4985 - mae: 0.8370 - val_loss: 9.7437 - val_mae: 1.9805\n",
      "Epoch 356/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.5859 - mae: 0.8467 - val_loss: 10.3548 - val_mae: 2.0635\n",
      "Epoch 357/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1754 - mae: 0.7131 - val_loss: 10.2602 - val_mae: 2.0824\n",
      "Epoch 358/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0546 - mae: 0.6879 - val_loss: 9.7694 - val_mae: 1.9992\n",
      "Epoch 359/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6214 - mae: 0.5281 - val_loss: 9.3770 - val_mae: 1.9712\n",
      "Epoch 360/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7391 - mae: 0.5872 - val_loss: 10.3898 - val_mae: 2.1053\n",
      "Epoch 361/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6842 - mae: 0.5490 - val_loss: 10.0673 - val_mae: 2.0358\n",
      "Epoch 362/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4774 - mae: 0.4713 - val_loss: 10.1402 - val_mae: 2.0455\n",
      "Epoch 363/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3175 - mae: 0.3937 - val_loss: 10.0318 - val_mae: 2.0582\n",
      "Epoch 364/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3333 - mae: 0.4208 - val_loss: 9.7824 - val_mae: 2.0512\n",
      "Epoch 365/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2928 - mae: 0.3878 - val_loss: 9.5368 - val_mae: 2.0216\n",
      "Epoch 366/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2411 - mae: 0.3459 - val_loss: 9.5994 - val_mae: 2.0028\n",
      "Epoch 367/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2709 - mae: 0.3786 - val_loss: 9.8483 - val_mae: 2.0135\n",
      "Epoch 368/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2884 - mae: 0.3814 - val_loss: 9.6898 - val_mae: 2.0533\n",
      "Epoch 369/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3333 - mae: 0.3949 - val_loss: 9.9005 - val_mae: 2.0504\n",
      "Epoch 370/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2808 - mae: 0.3532 - val_loss: 9.6063 - val_mae: 2.0044\n",
      "Epoch 371/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2128 - mae: 0.3332 - val_loss: 9.4250 - val_mae: 1.9802\n",
      "Epoch 372/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3919 - mae: 0.4411 - val_loss: 9.9558 - val_mae: 2.0542\n",
      "Epoch 373/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2941 - mae: 0.3769 - val_loss: 9.6547 - val_mae: 2.0035\n",
      "Epoch 374/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2303 - mae: 0.3334 - val_loss: 9.9694 - val_mae: 2.0323\n",
      "Epoch 375/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.1763 - mae: 0.3013 - val_loss: 9.7597 - val_mae: 2.0163\n",
      "Epoch 376/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2325 - mae: 0.3276 - val_loss: 9.8750 - val_mae: 2.0347\n",
      "Epoch 377/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2522 - mae: 0.3536 - val_loss: 9.5578 - val_mae: 2.0025\n",
      "Epoch 378/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1843 - mae: 0.2976 - val_loss: 9.2902 - val_mae: 1.9590\n",
      "Epoch 379/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2848 - mae: 0.3686 - val_loss: 9.7222 - val_mae: 2.0247\n",
      "Epoch 380/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4157 - mae: 0.4487 - val_loss: 9.5764 - val_mae: 2.0092\n",
      "Epoch 381/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3875 - mae: 0.4206 - val_loss: 9.6225 - val_mae: 2.0106\n",
      "Epoch 382/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6708 - mae: 0.5635 - val_loss: 11.2682 - val_mae: 2.1224\n",
      "Epoch 383/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5574 - mae: 0.4982 - val_loss: 10.7417 - val_mae: 2.1012\n",
      "Epoch 384/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5434 - mae: 0.4827 - val_loss: 11.3891 - val_mae: 2.1122\n",
      "Epoch 385/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.8157 - mae: 1.0950 - val_loss: 10.0312 - val_mae: 2.0582\n",
      "Epoch 386/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.6002 - mae: 1.0309 - val_loss: 9.4119 - val_mae: 2.0436\n",
      "Epoch 387/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.9365 - mae: 0.8844 - val_loss: 9.4938 - val_mae: 1.9616\n",
      "Epoch 388/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.8222 - mae: 1.0633 - val_loss: 9.4170 - val_mae: 2.0275\n",
      "Epoch 389/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.9666 - mae: 0.9364 - val_loss: 9.4589 - val_mae: 1.8814\n",
      "Epoch 390/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.6491 - mae: 0.8321 - val_loss: 9.4633 - val_mae: 1.9474\n",
      "Epoch 391/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.1175 - mae: 0.9681 - val_loss: 8.6711 - val_mae: 1.8765\n",
      "Epoch 392/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1245 - mae: 0.7089 - val_loss: 8.4065 - val_mae: 1.8640\n",
      "Epoch 393/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0031 - mae: 0.6739 - val_loss: 10.0314 - val_mae: 2.0428\n",
      "Epoch 394/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8314 - mae: 0.6141 - val_loss: 9.0031 - val_mae: 1.8813\n",
      "Epoch 395/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6799 - mae: 0.5559 - val_loss: 9.2425 - val_mae: 1.9345\n",
      "Epoch 396/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4132 - mae: 0.4346 - val_loss: 8.5520 - val_mae: 1.8410\n",
      "Epoch 397/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6082 - mae: 0.5310 - val_loss: 9.0604 - val_mae: 1.8803\n",
      "Epoch 398/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3197 - mae: 0.7622 - val_loss: 10.9546 - val_mae: 2.0680\n",
      "Epoch 399/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.2375 - mae: 0.7355 - val_loss: 8.1200 - val_mae: 1.8164\n",
      "Epoch 400/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.4542 - mae: 0.4508 - val_loss: 8.2534 - val_mae: 1.8201\n",
      "Epoch 401/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6216 - mae: 0.5214 - val_loss: 8.3700 - val_mae: 1.8525\n",
      "Epoch 402/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3442 - mae: 0.4132 - val_loss: 8.6935 - val_mae: 1.8745\n",
      "Epoch 403/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3321 - mae: 0.3984 - val_loss: 8.8798 - val_mae: 1.8815\n",
      "Epoch 404/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1948 - mae: 0.3067 - val_loss: 8.3936 - val_mae: 1.8478\n",
      "Epoch 405/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1780 - mae: 0.2996 - val_loss: 8.8427 - val_mae: 1.8625\n",
      "Epoch 406/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1559 - mae: 0.2798 - val_loss: 8.6490 - val_mae: 1.8555\n",
      "Epoch 407/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1427 - mae: 0.2675 - val_loss: 8.5799 - val_mae: 1.8364\n",
      "Epoch 408/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4402 - mae: 0.4451 - val_loss: 9.2617 - val_mae: 1.8900\n",
      "Epoch 409/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3452 - mae: 0.4055 - val_loss: 8.7995 - val_mae: 1.8719\n",
      "Epoch 410/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3166 - mae: 0.3808 - val_loss: 9.3479 - val_mae: 1.9077\n",
      "Epoch 411/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4995 - mae: 0.4227 - val_loss: 8.5943 - val_mae: 1.8604\n",
      "Epoch 412/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2409 - mae: 0.3366 - val_loss: 9.1381 - val_mae: 1.9054\n",
      "Epoch 413/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2762 - mae: 0.3576 - val_loss: 8.8139 - val_mae: 1.8628\n",
      "Epoch 414/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2405 - mae: 0.3318 - val_loss: 9.0004 - val_mae: 1.8830\n",
      "Epoch 415/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2108 - mae: 0.3175 - val_loss: 8.7228 - val_mae: 1.8334\n",
      "Epoch 416/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2197 - mae: 0.3129 - val_loss: 8.5005 - val_mae: 1.8402\n",
      "Epoch 417/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2317 - mae: 0.3250 - val_loss: 9.1428 - val_mae: 1.8885\n",
      "Epoch 418/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5055 - mae: 0.4737 - val_loss: 8.5924 - val_mae: 1.8524\n",
      "Epoch 419/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3156 - mae: 0.3691 - val_loss: 7.9605 - val_mae: 1.7803\n",
      "Epoch 420/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1696 - mae: 0.2859 - val_loss: 8.8185 - val_mae: 1.8809\n",
      "Epoch 421/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1049 - mae: 0.2304 - val_loss: 8.8087 - val_mae: 1.8742\n",
      "Epoch 422/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1107 - mae: 0.2339 - val_loss: 8.8516 - val_mae: 1.8810\n",
      "Epoch 423/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0788 - mae: 0.2043 - val_loss: 8.7985 - val_mae: 1.8690\n",
      "Epoch 424/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0782 - mae: 0.2041 - val_loss: 8.7547 - val_mae: 1.8629\n",
      "Epoch 425/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0796 - mae: 0.2000 - val_loss: 8.6832 - val_mae: 1.8448\n",
      "Epoch 426/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1109 - mae: 0.2326 - val_loss: 8.7095 - val_mae: 1.8519\n",
      "Epoch 427/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0948 - mae: 0.2130 - val_loss: 8.6726 - val_mae: 1.8420\n",
      "Epoch 428/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1069 - mae: 0.2278 - val_loss: 8.7161 - val_mae: 1.8494\n",
      "Epoch 429/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0888 - mae: 0.2027 - val_loss: 8.8039 - val_mae: 1.8668\n",
      "Epoch 430/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1053 - mae: 0.2253 - val_loss: 8.7127 - val_mae: 1.8727\n",
      "Epoch 431/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1663 - mae: 0.2773 - val_loss: 9.5271 - val_mae: 1.9330\n",
      "Epoch 432/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.4982 - mae: 0.4631 - val_loss: 8.6873 - val_mae: 1.8442\n",
      "Epoch 433/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.4410 - mae: 0.4188 - val_loss: 9.6391 - val_mae: 1.9459\n",
      "Epoch 434/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.8606 - mae: 0.5920 - val_loss: 9.0891 - val_mae: 1.8940\n",
      "Epoch 435/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.4853 - mae: 1.0091 - val_loss: 9.7703 - val_mae: 1.9138\n",
      "Epoch 436/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.6272 - mae: 0.8221 - val_loss: 8.6898 - val_mae: 1.8637\n",
      "Epoch 437/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.7117 - mae: 0.8572 - val_loss: 8.8822 - val_mae: 1.8793\n",
      "Epoch 438/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0522 - mae: 0.6610 - val_loss: 9.4849 - val_mae: 1.9366\n",
      "Epoch 439/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0788 - mae: 0.6630 - val_loss: 9.2603 - val_mae: 1.8821\n",
      "Epoch 440/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9559 - mae: 0.6487 - val_loss: 8.5520 - val_mae: 1.8491\n",
      "Epoch 441/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.6453 - mae: 0.5335 - val_loss: 8.7237 - val_mae: 1.8256\n",
      "Epoch 442/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6257 - mae: 0.5001 - val_loss: 8.2137 - val_mae: 1.7835\n",
      "Epoch 443/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4049 - mae: 0.4210 - val_loss: 7.9858 - val_mae: 1.7896\n",
      "Epoch 444/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2312 - mae: 0.3369 - val_loss: 8.0099 - val_mae: 1.7670\n",
      "Epoch 445/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2261 - mae: 0.3118 - val_loss: 8.6277 - val_mae: 1.8430\n",
      "Epoch 446/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2180 - mae: 0.3130 - val_loss: 7.9958 - val_mae: 1.7635\n",
      "Epoch 447/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3726 - mae: 0.4056 - val_loss: 8.7264 - val_mae: 1.8412\n",
      "Epoch 448/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3971 - mae: 0.4226 - val_loss: 8.2651 - val_mae: 1.7914\n",
      "Epoch 449/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4366 - mae: 0.4349 - val_loss: 8.3839 - val_mae: 1.8225\n",
      "Epoch 450/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2563 - mae: 0.3282 - val_loss: 8.3625 - val_mae: 1.8318\n",
      "Epoch 451/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2164 - mae: 0.3143 - val_loss: 8.7187 - val_mae: 1.8556\n",
      "Epoch 452/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3855 - mae: 0.4059 - val_loss: 8.7407 - val_mae: 1.8822\n",
      "Epoch 453/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4585 - mae: 0.4433 - val_loss: 8.3290 - val_mae: 1.8114\n",
      "Epoch 454/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4660 - mae: 0.4469 - val_loss: 8.7342 - val_mae: 1.8381\n",
      "Epoch 455/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4171 - mae: 0.4118 - val_loss: 7.7157 - val_mae: 1.7188\n",
      "Epoch 456/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5109 - mae: 0.4478 - val_loss: 8.2041 - val_mae: 1.7927\n",
      "Epoch 457/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5910 - mae: 0.4735 - val_loss: 7.9318 - val_mae: 1.7916\n",
      "Epoch 458/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2824 - mae: 0.3440 - val_loss: 8.6590 - val_mae: 1.8551\n",
      "Epoch 459/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.4387 - mae: 0.4405 - val_loss: 7.9531 - val_mae: 1.7637\n",
      "Epoch 460/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.4019 - mae: 0.4268 - val_loss: 8.1126 - val_mae: 1.7858\n",
      "Epoch 461/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2551 - mae: 0.3210 - val_loss: 8.2178 - val_mae: 1.8002\n",
      "Epoch 462/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2497 - mae: 0.3280 - val_loss: 8.0375 - val_mae: 1.7820\n",
      "Epoch 463/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1865 - mae: 0.2723 - val_loss: 7.9991 - val_mae: 1.7623\n",
      "Epoch 464/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.3258 - mae: 0.3790 - val_loss: 7.6216 - val_mae: 1.7677\n",
      "Epoch 465/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6825 - mae: 0.5332 - val_loss: 7.8937 - val_mae: 1.7663\n",
      "Epoch 466/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5695 - mae: 0.4977 - val_loss: 8.9161 - val_mae: 1.8865\n",
      "Epoch 467/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3712 - mae: 0.3965 - val_loss: 8.1957 - val_mae: 1.7980\n",
      "Epoch 468/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2355 - mae: 0.3308 - val_loss: 8.4958 - val_mae: 1.8447\n",
      "Epoch 469/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1352 - mae: 0.2449 - val_loss: 8.0671 - val_mae: 1.7835\n",
      "Epoch 470/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2982 - mae: 0.3553 - val_loss: 8.2638 - val_mae: 1.7853\n",
      "Epoch 471/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5476 - mae: 0.4940 - val_loss: 8.2309 - val_mae: 1.8012\n",
      "Epoch 472/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2576 - mae: 0.3374 - val_loss: 7.9830 - val_mae: 1.7746\n",
      "Epoch 473/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3579 - mae: 0.3767 - val_loss: 8.1241 - val_mae: 1.7830\n",
      "Epoch 474/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2396 - mae: 0.3126 - val_loss: 8.0658 - val_mae: 1.8060\n",
      "Epoch 475/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1414 - mae: 0.2476 - val_loss: 8.1389 - val_mae: 1.7854\n",
      "Epoch 476/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0889 - mae: 0.1947 - val_loss: 8.0846 - val_mae: 1.7839\n",
      "Epoch 477/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1217 - mae: 0.2157 - val_loss: 8.2990 - val_mae: 1.8294\n",
      "Epoch 478/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1979 - mae: 0.2882 - val_loss: 8.2745 - val_mae: 1.8131\n",
      "Epoch 479/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.1999 - mae: 0.2887 - val_loss: 8.2763 - val_mae: 1.7991\n",
      "Epoch 480/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1756 - mae: 0.2696 - val_loss: 8.4253 - val_mae: 1.8217\n",
      "Epoch 481/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.1237 - mae: 0.2310 - val_loss: 8.4842 - val_mae: 1.8218\n",
      "Epoch 482/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.1935 - mae: 0.2696 - val_loss: 8.6520 - val_mae: 1.8338\n",
      "Epoch 483/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2383 - mae: 0.3218 - val_loss: 8.5407 - val_mae: 1.8423\n",
      "Epoch 484/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.2744 - mae: 0.3336 - val_loss: 8.8136 - val_mae: 1.8578\n",
      "Epoch 485/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3285 - mae: 0.3666 - val_loss: 8.0889 - val_mae: 1.7949\n",
      "Epoch 486/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3390 - mae: 0.3764 - val_loss: 8.7148 - val_mae: 1.8506\n",
      "Epoch 487/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.3295 - mae: 0.3756 - val_loss: 8.2168 - val_mae: 1.7824\n",
      "Epoch 488/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5364 - mae: 0.4589 - val_loss: 8.2867 - val_mae: 1.8012\n",
      "Epoch 489/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.0538 - mae: 0.6696 - val_loss: 9.4870 - val_mae: 1.9229\n",
      "Epoch 490/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.6060 - mae: 0.7932 - val_loss: 7.6290 - val_mae: 1.7527\n",
      "Epoch 491/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.1271 - mae: 0.6665 - val_loss: 8.0982 - val_mae: 1.8038\n",
      "Epoch 492/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.7097 - mae: 0.8293 - val_loss: 8.4082 - val_mae: 1.8590\n",
      "Epoch 493/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.0692 - mae: 0.6539 - val_loss: 8.1760 - val_mae: 1.8261\n",
      "Epoch 494/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.2050 - mae: 0.7375 - val_loss: 8.2776 - val_mae: 1.7836\n",
      "Epoch 495/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.6624 - mae: 0.5590 - val_loss: 10.5371 - val_mae: 2.0366\n",
      "Epoch 496/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8131 - mae: 0.5998 - val_loss: 7.7519 - val_mae: 1.7390\n",
      "Epoch 497/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0364 - mae: 0.6818 - val_loss: 8.4804 - val_mae: 1.8314\n",
      "Epoch 498/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9692 - mae: 0.6413 - val_loss: 8.3846 - val_mae: 1.8159\n",
      "Epoch 499/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1240 - mae: 0.6818 - val_loss: 7.9756 - val_mae: 1.7610\n",
      "Epoch 500/500\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6546 - mae: 0.5155 - val_loss: 9.0906 - val_mae: 1.8722\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x265cecd8370>"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "model = build_model(X_train.shape[1])\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-23T11:49:25.009444Z",
     "start_time": "2024-11-23T11:48:40.785839Z"
    }
   },
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:54:32.274809Z",
     "start_time": "2024-11-23T11:54:31.205621Z"
    }
   },
   "outputs": [],
   "source": [
    "#get image pairs\n",
    "base_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "#label path\n",
    "lbl_path = os.path.join(base_path, 'Data/labels/test_template_matching.json')\n",
    "\n",
    "#source and query images\n",
    "s_img_path = os.path.join(base_path, 'Data/map_train/51.99908_4.373749.png')\n",
    "q_img_path = os.path.join(base_path, 'Data/test_template_matching')\n",
    "\n",
    "#for now source path is constant\n",
    "s_img = cv2.imread(s_img_path)\n",
    "\n",
    "with open(lbl_path, 'r') as file:\n",
    "    label = json.load(file)\n",
    "\n",
    "images = []\n",
    "templates = []\n",
    "for file in os.listdir(q_img_path):\n",
    "    if file.endswith(\".jpg\") or file.endswith(\".png\") or file.endswith(\".jpeg\"):\n",
    "            q_img = cv2.imread(os.path.join(q_img_path, file))\n",
    "            images.append([q_img[:, :, :3], s_img[:,:,:3]]) \n",
    "            gps = find_specific_lookup(label, '51.99908_4.373749.png', file)\n",
    "            \n",
    "            templates.append((q_img[:, :, :3], gps))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_features_for_test(templates, source_image):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    kp_source, des_source = sift.detectAndCompute(source_image, None)\n",
    "    \n",
    "    for template, obj in templates:\n",
    "        kp_template, des_template = sift.detectAndCompute(template, None)\n",
    "        gps_coords = obj['gps_coords']\n",
    "        # Match features\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(des_template, des_source, k=2)\n",
    "        \n",
    "        # Lowe's ratio test\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good_matches.append(m)\n",
    "        \n",
    "        # Extract matched keypoints\n",
    "        src_pts = np.float32([kp_template[m.queryIdx].pt for m in good_matches]).reshape(-1, 2)\n",
    "        dst_pts = np.float32([kp_source[m.trainIdx].pt for m in good_matches]).reshape(-1, 2)\n",
    "        \n",
    "        # Flatten and combine features\n",
    "        src_flat = src_pts.flatten()\n",
    "        dst_flat = dst_pts.flatten()\n",
    "        input_features = np.concatenate([src_flat, dst_flat])\n",
    "        \n",
    "        # Append to feature list\n",
    "        feature_list.append(input_features)\n",
    "        label_list.append(gps_coords)  # GPS coordinates of this template image\n",
    "    # max_len = max(len(features) for features in feature_list)\n",
    "    max_len = 504\n",
    "    padded_features = [np.pad(features, (0, max_len - len(features))) for features in feature_list]\n",
    "\n",
    "    return np.array(padded_features), np.array(label_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-23T11:55:45.883610Z",
     "start_time": "2024-11-23T11:55:45.863313Z"
    }
   },
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_test, y_train = extract_features_for_test(templates, s_img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-23T11:56:31.291105Z",
     "start_time": "2024-11-23T11:55:46.367973Z"
    }
   },
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 504)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-23T11:56:39.651933Z",
     "start_time": "2024-11-23T11:56:39.638257Z"
    }
   },
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51.991689  4.375115]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step\n",
      "[[49.83817    4.2187595]]\n",
      "[51.991788  4.362447]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step\n",
      "[[51.253807   4.4347596]]\n",
      "[51.99178   4.362269]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "[[47.062      4.1319656]]\n",
      "[51.991911  4.380817]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "[[51.38058    4.4926515]]\n",
      "[51.991973  4.368326]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "[[55.03424   4.811132]]\n",
      "[51.99198   4.362729]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "[[48.790485   4.3495355]]\n",
      "[51.991992  4.375029]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "[[50.74972    4.6432676]]\n",
      "[51.99202   4.388936]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "[[48.503513  4.178122]]\n",
      "[51.99203   4.380806]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[54.583443   4.7392645]]\n",
      "[51.992081  4.363168]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "[[51.874847  4.667581]]\n",
      "[51.992156  4.363652]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step\n",
      "[[50.566566  4.417961]]\n",
      "[51.992161  4.38868 ]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[49.184677   5.6572347]]\n",
      "[51.992194  4.377034]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step\n",
      "[[49.991882  4.416356]]\n",
      "[51.992202  4.383391]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "[[51.37589    4.4240074]]\n",
      "[51.99222  4.38671]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "[[54.898705   4.9531636]]\n",
      "[51.992334  4.371455]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "[[52.301044   4.5554004]]\n",
      "[51.992397  4.385285]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "[[49.040276  4.212919]]\n",
      "[51.99244   4.365132]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[63.13497    5.6293855]]\n",
      "[51.992476  4.372469]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[51.654613   4.4430523]]\n",
      "[51.992592  4.369023]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[45.88172    4.0648985]]\n",
      "[51.992616  4.381478]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[52.029324   4.5573726]]\n",
      "[51.992748  4.373854]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "[[46.992485   4.0509725]]\n",
      "[51.992837  4.378495]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[50.63094   4.513701]]\n",
      "[51.992959  4.375218]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[52.665977  4.660682]]\n",
      "[51.99295   4.384892]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "[[57.82986  4.90923]]\n",
      "[51.992996  4.387848]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step\n",
      "[[49.110107  4.036731]]\n",
      "[51.993022  4.365558]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[42.692123  3.28802 ]]\n",
      "[51.993029  4.387888]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step\n",
      "[[41.15752   4.249511]]\n",
      "[51.993072  4.364632]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "[[44.105267   4.0761724]]\n",
      "[51.99308  4.36856]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[50.65858    4.2951803]]\n",
      "[51.993153  4.387307]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "[[50.650513  4.355609]]\n",
      "[51.993157  4.363119]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "[[46.77603    4.2013526]]\n",
      "[51.993288  4.384992]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "[[54.342773   4.6112933]]\n",
      "[51.993331  4.385202]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "[[51.9845     2.3173602]]\n",
      "[51.993423  4.378585]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[59.05355    5.1669173]]\n",
      "[51.993438  4.363171]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[46.861458  4.140777]]\n",
      "[51.993445  4.378949]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "[[51.89305    4.6125135]]\n",
      "[51.993496  4.3874  ]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[43.174442   3.7076445]]\n",
      "[51.993498  4.388501]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "[[45.524487   3.5203638]]\n",
      "[51.993566  4.381887]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "[[51.56652   4.437202]]\n",
      "[51.993566  4.385479]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "[[51.895683   4.6603026]]\n",
      "[51.993581  4.385709]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "[[49.286804   4.1573553]]\n",
      "[51.993598  4.380021]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "[[48.42712   4.232808]]\n",
      "[51.993605  4.379138]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "[[49.721615   4.3064284]]\n",
      "[51.993677  4.387244]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "[[47.78789   4.265892]]\n",
      "[51.993805  4.383685]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "[[53.90948    4.6322722]]\n",
      "[51.993842  4.37936 ]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "[[52.824535  4.653888]]\n",
      "[51.993896  4.371266]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "[[47.5664     4.2016115]]\n",
      "[51.994068  4.377423]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "[[51.820946  4.57388 ]]\n",
      "[51.99421   4.380807]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[52.625916  4.786313]]\n",
      "[51.994244  4.380951]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "[[56.271454   4.9904623]]\n",
      "[51.994282  4.384697]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "[[55.8652     4.9632096]]\n",
      "[51.994325  4.364398]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "[[51.133854   4.7910395]]\n",
      "[51.994397  4.37478 ]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "[[51.09556    4.3776436]]\n",
      "[51.994438  4.38376 ]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "[[55.48176   4.984123]]\n",
      "[51.994506  4.388227]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "[[49.386112   3.1036186]]\n",
      "[51.994585  4.379113]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "[[48.384525  4.335034]]\n",
      "[51.994679  4.379184]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "[[57.285362  4.949611]]\n",
      "[51.99467   4.378967]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "[[52.53565  4.71505]]\n",
      "[51.994698  4.362938]\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "[[49.072777   4.1224036]]\n",
      "[51.9946    4.373003]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[129], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(y_train[i])\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# print(test_input.shape)\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m point2 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_input\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(point2)\n\u001B[0;32m      8\u001B[0m distance \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m haversine(y_train[i], point2[\u001B[38;5;241m0\u001B[39m], unit\u001B[38;5;241m=\u001B[39mUnit\u001B[38;5;241m.\u001B[39mMETERS)\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:448\u001B[0m, in \u001B[0;36mTensorFlowTrainer.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks)\u001B[0m\n\u001B[0;32m    443\u001B[0m \u001B[38;5;129m@traceback_utils\u001B[39m\u001B[38;5;241m.\u001B[39mfilter_traceback\n\u001B[0;32m    444\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\n\u001B[0;32m    445\u001B[0m     \u001B[38;5;28mself\u001B[39m, x, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m, steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, callbacks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    446\u001B[0m ):\n\u001B[0;32m    447\u001B[0m     \u001B[38;5;66;03m# Create an iterator that yields batches of input data.\u001B[39;00m\n\u001B[1;32m--> 448\u001B[0m     epoch_iterator \u001B[38;5;241m=\u001B[39m \u001B[43mTFEpochIterator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    449\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    450\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    451\u001B[0m \u001B[43m        \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdistribute_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    454\u001B[0m \u001B[43m        \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msteps_per_execution\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    457\u001B[0m     \u001B[38;5;66;03m# Container that configures and calls callbacks.\u001B[39;00m\n\u001B[0;32m    458\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:666\u001B[0m, in \u001B[0;36mTFEpochIterator.__init__\u001B[1;34m(self, distribute_strategy, *args, **kwargs)\u001B[0m\n\u001B[0;32m    664\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    665\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distribute_strategy \u001B[38;5;241m=\u001B[39m distribute_strategy\n\u001B[1;32m--> 666\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    667\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dataset, tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mDistributedDataset):\n\u001B[0;32m    668\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distribute_strategy\u001B[38;5;241m.\u001B[39mexperimental_distribute_dataset(\n\u001B[0;32m    669\u001B[0m         dataset\n\u001B[0;32m    670\u001B[0m     )\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:675\u001B[0m, in \u001B[0;36mTFEpochIterator._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    674\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_iterator\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 675\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_tf_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py:140\u001B[0m, in \u001B[0;36mArrayDataAdapter.get_tf_dataset\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m indices\n\u001B[0;32m    135\u001B[0m \u001B[38;5;66;03m# We prefetch a single element. Computing large permutations can take\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;66;03m# quite a while so we don't want to wait for prefetching over an epoch\u001B[39;00m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;66;03m# boundary to trigger the next permutation. On the other hand, too many\u001B[39;00m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;66;03m# simultaneous shuffles can contend on a hardware level and degrade all\u001B[39;00m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;66;03m# performance.\u001B[39;00m\n\u001B[1;32m--> 140\u001B[0m indices_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mindices_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpermutation\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mprefetch(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mslice_batch_indices\u001B[39m(indices):\n\u001B[0;32m    143\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001B[39;00m\n\u001B[0;32m    144\u001B[0m \n\u001B[0;32m    145\u001B[0m \u001B[38;5;124;03m    This step can be accomplished in several ways. The most natural is\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;124;03m        A Dataset of batched indices.\u001B[39;00m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2341\u001B[0m, in \u001B[0;36mDatasetV2.map\u001B[1;34m(self, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001B[0m\n\u001B[0;32m   2336\u001B[0m \u001B[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001B[39;00m\n\u001B[0;32m   2337\u001B[0m \u001B[38;5;66;03m# dataset_ops).\u001B[39;00m\n\u001B[0;32m   2338\u001B[0m \u001B[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001B[39;00m\n\u001B[0;32m   2339\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m map_op\n\u001B[1;32m-> 2341\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmap_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_v2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2342\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2343\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2345\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdeterministic\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdeterministic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2346\u001B[0m \u001B[43m    \u001B[49m\u001B[43msynchronous\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynchronous\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2347\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_unbounded_threadpool\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_unbounded_threadpool\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2349\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:43\u001B[0m, in \u001B[0;36m_map_v2\u001B[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001B[0m\n\u001B[0;32m     38\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m deterministic \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m debug_mode\u001B[38;5;241m.\u001B[39mDEBUG_MODE:\n\u001B[0;32m     39\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m     40\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `deterministic` argument has no effect unless the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     41\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`num_parallel_calls` argument is specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     42\u001B[0m     )\n\u001B[1;32m---> 43\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MapDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[43m      \u001B[49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[43m      \u001B[49m\u001B[43mpreserve_cardinality\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[43m      \u001B[49m\u001B[43mforce_synchronous\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msynchronous\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msynchronous\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     49\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m synchronous:\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:157\u001B[0m, in \u001B[0;36m_MapDataset.__init__\u001B[1;34m(self, input_dataset, map_func, force_synchronous, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001B[0m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_inter_op_parallelism \u001B[38;5;241m=\u001B[39m use_inter_op_parallelism\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_preserve_cardinality \u001B[38;5;241m=\u001B[39m preserve_cardinality\n\u001B[1;32m--> 157\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m \u001B[43mstructured_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mStructuredFunctionWrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transformation_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_legacy_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_legacy_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_force_synchronous \u001B[38;5;241m=\u001B[39m force_synchronous\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name \u001B[38;5;241m=\u001B[39m name\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:265\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__\u001B[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[0;32m    258\u001B[0m       warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    259\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    260\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moption is set, this option does not apply to tf.data functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    261\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo force eager execution of tf.data functions, please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    262\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    263\u001B[0m     fn_factory \u001B[38;5;241m=\u001B[39m trace_tf_function(defun_kwargs)\n\u001B[1;32m--> 265\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function \u001B[38;5;241m=\u001B[39m \u001B[43mfn_factory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;66;03m# There is no graph to add in eager mode.\u001B[39;00m\n\u001B[0;32m    267\u001B[0m add_to_graph \u001B[38;5;241m&\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly()\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1251\u001B[0m, in \u001B[0;36mFunction.get_concrete_function\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1249\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_concrete_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1250\u001B[0m   \u001B[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001B[39;00m\n\u001B[1;32m-> 1251\u001B[0m   concrete \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_concrete_function_garbage_collected(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1252\u001B[0m   concrete\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   1253\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m concrete\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1221\u001B[0m, in \u001B[0;36mFunction._get_concrete_function_garbage_collected\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1219\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1220\u001B[0m     initializers \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m-> 1221\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_initializers_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitializers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1222\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialize_uninitialized_variables(initializers)\n\u001B[0;32m   1224\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[0;32m   1225\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m   1226\u001B[0m   \u001B[38;5;66;03m# version which is guaranteed to never create variables.\u001B[39;00m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:696\u001B[0m, in \u001B[0;36mFunction._initialize\u001B[1;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[0;32m    691\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_scoped_tracing_options(\n\u001B[0;32m    692\u001B[0m     variable_capturing_scope,\n\u001B[0;32m    693\u001B[0m     tracing_compilation\u001B[38;5;241m.\u001B[39mScopeType\u001B[38;5;241m.\u001B[39mVARIABLE_CREATION,\n\u001B[0;32m    694\u001B[0m )\n\u001B[0;32m    695\u001B[0m \u001B[38;5;66;03m# Force the definition of the function for these arguments\u001B[39;00m\n\u001B[1;32m--> 696\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_variable_creation_fn \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrace_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    697\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[0;32m    698\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    700\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvalid_creator_scope\u001B[39m(\u001B[38;5;241m*\u001B[39munused_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39munused_kwds):\n\u001B[0;32m    701\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001B[0m, in \u001B[0;36mtrace_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    175\u001B[0m     args \u001B[38;5;241m=\u001B[39m tracing_options\u001B[38;5;241m.\u001B[39minput_signature\n\u001B[0;32m    176\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m--> 178\u001B[0m   concrete_function \u001B[38;5;241m=\u001B[39m \u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    179\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtracing_options\u001B[49m\n\u001B[0;32m    180\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tracing_options\u001B[38;5;241m.\u001B[39mbind_graph_to_function:\n\u001B[0;32m    183\u001B[0m   concrete_function\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001B[0m, in \u001B[0;36m_maybe_define_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    282\u001B[0m   target_func_type \u001B[38;5;241m=\u001B[39m lookup_func_type\n\u001B[1;32m--> 283\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m \u001B[43m_create_concrete_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget_func_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlookup_func_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtracing_options\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tracing_options\u001B[38;5;241m.\u001B[39mfunction_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    288\u001B[0m   tracing_options\u001B[38;5;241m.\u001B[39mfunction_cache\u001B[38;5;241m.\u001B[39madd(\n\u001B[0;32m    289\u001B[0m       concrete_function, current_func_context\n\u001B[0;32m    290\u001B[0m   )\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:340\u001B[0m, in \u001B[0;36m_create_concrete_function\u001B[1;34m(function_type, type_context, func_graph, tracing_options)\u001B[0m\n\u001B[0;32m    331\u001B[0m output_type \u001B[38;5;241m=\u001B[39m trace_type\u001B[38;5;241m.\u001B[39mfrom_value(\n\u001B[0;32m    332\u001B[0m     traced_func_graph\u001B[38;5;241m.\u001B[39mstructured_outputs, type_context\n\u001B[0;32m    333\u001B[0m )\n\u001B[0;32m    334\u001B[0m traced_func_type \u001B[38;5;241m=\u001B[39m function_type_lib\u001B[38;5;241m.\u001B[39mFunctionType(\n\u001B[0;32m    335\u001B[0m     function_type\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mvalues(),\n\u001B[0;32m    336\u001B[0m     traced_func_graph\u001B[38;5;241m.\u001B[39mfunction_captures\u001B[38;5;241m.\u001B[39mcapture_types,\n\u001B[0;32m    337\u001B[0m     return_annotation\u001B[38;5;241m=\u001B[39moutput_type,\n\u001B[0;32m    338\u001B[0m )\n\u001B[1;32m--> 340\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m \u001B[43mconcrete_function_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mConcreteFunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_func_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraced_func_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraced_func_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    343\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtracing_options\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattributes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[39;49;00m\n\u001B[0;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# scope. This is not the default behavior since it gets used in some\u001B[39;49;00m\n\u001B[0;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# places (like Keras) where the FuncGraph lives longer than the\u001B[39;49;00m\n\u001B[0;32m    347\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# ConcreteFunction.\u001B[39;49;00m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshared_func_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    350\u001B[0m _set_arg_keywords(concrete_function)\n\u001B[0;32m    351\u001B[0m transform\u001B[38;5;241m.\u001B[39mcall_concrete_function_callbacks(concrete_function)\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1075\u001B[0m, in \u001B[0;36mConcreteFunction.from_func_graph\u001B[1;34m(cls, graph, function_type, attrs, shared_func_graph)\u001B[0m\n\u001B[0;32m   1073\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m   1074\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_func_graph\u001B[39m(\u001B[38;5;28mcls\u001B[39m, graph, function_type, attrs, shared_func_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m-> 1075\u001B[0m   atomic_fn \u001B[38;5;241m=\u001B[39m \u001B[43matomic_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_func_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1076\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_inference_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_type\u001B[49m\n\u001B[0;32m   1077\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1078\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m ConcreteFunction(atomic_fn, shared_func_graph\u001B[38;5;241m=\u001B[39mshared_func_graph)\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\CASSINI Hackathon\\CASSINI\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:540\u001B[0m, in \u001B[0;36mfrom_func_graph\u001B[1;34m(name, graph, attrs, function_type, overwrite)\u001B[0m\n\u001B[0;32m    538\u001B[0m   output_names \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    539\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m graph\u001B[38;5;241m.\u001B[39m_c_graph\u001B[38;5;241m.\u001B[39mget() \u001B[38;5;28;01mas\u001B[39;00m c_graph:  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m--> 540\u001B[0m   fn \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tf_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTF_GraphToFunction_wrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    541\u001B[0m \u001B[43m      \u001B[49m\u001B[43mc_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    542\u001B[0m \u001B[43m      \u001B[49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    543\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    544\u001B[0m \u001B[43m      \u001B[49m\u001B[43m[\u001B[49m\u001B[43mo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_c_op\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mo\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moperations\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    545\u001B[0m \u001B[43m      \u001B[49m\u001B[43m[\u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_as_tf_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    546\u001B[0m \u001B[43m      \u001B[49m\u001B[43m[\u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_as_tf_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    547\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    548\u001B[0m \u001B[43m      \u001B[49m\u001B[43m[\u001B[49m\u001B[43mo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_c_op\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mo\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontrol_outputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    549\u001B[0m \u001B[43m      \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# control_output_names\u001B[39;49;00m\n\u001B[0;32m    550\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    551\u001B[0m \u001B[43m      \u001B[49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_str\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    552\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    554\u001B[0m attrs \u001B[38;5;241m=\u001B[39m attributes_lib\u001B[38;5;241m.\u001B[39mparse_func_attrs(attrs \u001B[38;5;129;01mor\u001B[39;00m {})\n\u001B[0;32m    555\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m attr_name, attr_value \u001B[38;5;129;01min\u001B[39;00m attrs\u001B[38;5;241m.\u001B[39mitems():\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from haversine import haversine, Unit\n",
    "distance = 0\n",
    "for i, test_input in enumerate(X_test):\n",
    "    print(y_train[i])\n",
    "    # print(test_input.shape)\n",
    "    point2 = model.predict(test_input.reshape(1, -1))\n",
    "    print(point2)\n",
    "    distance += haversine(y_train[i], point2[0], unit=Unit.METERS)\n",
    "print(len(X_test))\n",
    "print(distance/len(X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-23T11:59:21.193631Z",
     "start_time": "2024-11-23T11:59:16.562165Z"
    }
   },
   "execution_count": 129
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
